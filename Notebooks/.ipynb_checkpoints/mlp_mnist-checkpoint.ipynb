{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "from imageio import imread\n",
    "from sklearn.metrics import accuracy_score \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and check for existance\n",
    "root_dir = os.path.abspath('D:\\Portfolio')\n",
    "data_dir = os.path.join(root_dir,'data\\MNIST')\n",
    "\n",
    "assert os.path.exists(root_dir) == True and os.path.exists(data_dir) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information \n",
    "\n",
    "This dataset used in this project is a subset of the [MNIST](http://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology) database developed by Yann LeCun, Corina Cortes, and Christopher Burger. This popular database holds a large collection of handwritten digits commonly used to train image processing systems, or in our case, train a neural network for OCR (optical character recognition) applications. \n",
    "\n",
    "The [dataset](https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/) contains a total of 70,000 black and white handwritten digits in a 28x28 pixel image. These images are split into 49,000 training (labeled) and 21,000 test images (unlabeled). \n",
    "\n",
    "The .csv files contain the filenames and as well as their associated labels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename  label\n",
      "0    0.png      4\n",
      "1    1.png      9\n",
      "2    2.png      1\n",
      "3    3.png      7\n",
      "4    4.png      3\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir,'test.csv'))\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data is loaded into a (2,22,n) size matrix in grayscale values, which corresponds to values of 0 as white and 255 as black. Files are iterated over and temporarily stored as a dictionary before converted into a numpy array. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 3868.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2251dfa6518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Training images\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    img_path = os.path.join(data_dir,'Images\\\\train',img_name)\n",
    "    img = imread(img_path, as_gray = True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    " \n",
    "train_mat = np.stack(temp)\n",
    "\n",
    "# Test images\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    img_path = os.path.join(data_dir,'Images\\\\test',img_name)\n",
    "    img = imread(img_path, as_gray = True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "\n",
    "test_mat = np.stack(temp)\n",
    "\n",
    "# View random image for example\n",
    "img_name = np.random.RandomState().choice(train.filename)\n",
    "img_path = os.path.join(data_dir,'Images\\\\train',img_name)\n",
    "\n",
    "img = imread(img_path)\n",
    "\n",
    "print('Filename:',img_name)\n",
    "plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is then split into subsets for the purposes of training and validating the neural network. Here, we use a ratio of 70:30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_frac = int(train_mat.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_mat[:val_frac], train_mat[val_frac:]\n",
    "train_y, val_y = train.label.values[:val_frac], train.label.values[val_frac:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network architecture \n",
    "\n",
    "Here, we define the architecture for the neural network. Nodes for the input and output layers are determined by the structure of the input (28x28 = 784 pixels) and output (10 categories) data, respectively. For the hidden layer, 256 nodes are used. \n",
    "\n",
    "Training data is fed into the neural network in mini-batches of size 128. Compared to the traditional method of feeding images into our model one-by-one (stochastic gradient descent), the mini-batch method has several advantages which include: faster computation times and the prevention of the model from converging onto local minima of the loss function. \n",
    "\n",
    "For the single hidden layer, the ReLu activation function is used for a multitude of reasons (see https://bit.ly/2wv3kcd). The softmax function is used for the output layer due to the multi-class nature of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nodes in each layer \n",
    "n_input = 28*28\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "\n",
    "# Initialize placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "# Learning variables \n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "n_batch = 128\n",
    "\n",
    "\n",
    "# Define weights and biases of NN \n",
    "weights = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "        'output': tf.Variable(tf.random_normal([n_hidden, n_output]))}\n",
    "\n",
    "biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'output': tf.Variable(tf.random_normal([n_output]))}\n",
    "\n",
    "# Define computation graphs \n",
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']\n",
    "\n",
    "# Define loss function  \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = output_layer))\n",
    "\n",
    "# Set optimizer for loss function  \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Before we initialize our training cycle, we first need to define two helper functions. The first function scal_2_onehot is used to encode the labels as one-hot vectors. Typically, this step is needed to convert categorical variables into numerical values for input into the machine learning model. In our case, the categorical variables are labels ranging from 0 to 9, meaning that our labelled data is inherently scalar encoded. This is something we would ideally like to avoid as the neural network may intepret the labels as different weights. Encoding the labelled data as one-hot vectors allows us to assume each category has equal weight and ensures it has no affect on the calculation of the loss function during the backpropagation step of the neural network. Note that TensorFlow has a function to do this, however it is quite computationally inefficient to evaluate the object during the session. \n",
    "\n",
    "The second function is used to create batches to feed the input data into the neural network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scal_2_onehot(scal, n_classes):\n",
    "    \"Convert scalars to one-hot vectors\"\n",
    "    \n",
    "    n_labels = scal.shape[0]\n",
    "    ind_offset = np.arange(0,n_labels)* n_classes\n",
    "    one_hot = np.zeros((n_labels, n_classes))\n",
    "    one_hot.flat[ind_offset + scal.ravel()] = 1\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def make_batch(n_batch, n_input, n_output, train_x, train_y):\n",
    "    \"Create batch with random samples in one-hot vectors\"\n",
    "    \n",
    "    batch_mask = np.random.RandomState().choice(train_x.shape[0], n_batch)\n",
    "    \n",
    "    batch_x = train_x[batch_mask].reshape(-1,n_input)\n",
    "    batch_x = batch_x / batch_x.max()\n",
    "    \n",
    "    batch_y = scal_2_onehot(train_y[batch_mask], n_output)\n",
    "    \n",
    "    return batch_x, batch_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training session \n",
    "\n",
    "Finally, we can train our model and test it using the validation dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in process...\n",
      "\n",
      "Epoch (1/10):\n",
      " Training loss = 5.92429\n",
      "Epoch (2/10):\n",
      " Training loss = 1.15539\n",
      "Epoch (3/10):\n",
      " Training loss = 0.63891\n",
      "Epoch (4/10):\n",
      " Training loss = 0.33832\n",
      "Epoch (5/10):\n",
      " Training loss = 0.21810\n",
      "Epoch (6/10):\n",
      " Training loss = 0.19556\n",
      "Epoch (7/10):\n",
      " Training loss = 0.15259\n",
      "Epoch (8/10):\n",
      " Training loss = 0.13901\n",
      "Epoch (9/10):\n",
      " Training loss = 0.14284\n",
      "Epoch (10/10):\n",
      " Training loss = 0.13190\n",
      "\n",
      "Training complete\n",
      "Validation Accuracy: 0.954966\n",
      "Computation time: 00:00:08\n"
     ]
    }
   ],
   "source": [
    "t_start = time.clock()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # create initialized variables \n",
    "    sess.run(init)\n",
    "    \n",
    "    print('Training in process...\\n')\n",
    "\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        avg_loss = 0\n",
    "        total_batch = int(train.shape[0]/n_batch)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = make_batch(n_batch, n_input, n_output, train_x, train_y)\n",
    "            _, c = sess.run([optimizer, loss], feed_dict = {x: batch_x, y: batch_y})\n",
    "            \n",
    "            avg_loss += c / total_batch\n",
    "            \n",
    "        print('Epoch', '(' + str(j + 1) + '/' + str(epochs) + '):\\n', \n",
    "              'Training loss =', '{:.5f}'.format(avg_loss))\n",
    "        \n",
    "    t_comput = time.clock() - t_start\n",
    "    \n",
    "    # Test predictions on validation data \n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, 'float'))\n",
    "    \n",
    "    print('\\nTraining complete\\n' + 'Validation Accuracy:', \n",
    "          accuracy.eval({x: val_x.reshape(-1, n_input), y: scal_2_onehot(val_y, n_output)}))\n",
    "    \n",
    "    print('Computation time:', time.strftime('%H:%M:%S',time.gmtime(t_comput)))\n",
    "    \n",
    "    # Find predictions on test data\n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({x: test_mat.reshape(-1, n_input)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions of test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is the number 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model on single image\n",
    "rng = np.random.randint(0,test_mat.shape[0])\n",
    "test_img = test_mat[rng,:,:]\n",
    "plt.imshow(test_img,cmap = 'gray')\n",
    "print('\\nPrediction is the number',pred[rng])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
